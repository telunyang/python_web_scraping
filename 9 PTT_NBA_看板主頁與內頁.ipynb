{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯入套件\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as req\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一般用法\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得新聞列表\n",
    "url = \"https://www.ptt.cc/bbs/NBA/index.html\" \n",
    "\n",
    "# 用 requests 的 get 方法把網頁抓下來\n",
    "res = req.get(url) \n",
    "\n",
    "# 指定 lxml 作為解析器\n",
    "soup = bs(res.text, \"lxml\") \n",
    "\n",
    "# 建立 list 來放置列表資訊\n",
    "list_posts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清空放置列表資訊的變數\n",
    "list_posts.clear()\n",
    "\n",
    "# 取得 列表 的文字與超連結\n",
    "for a in soup.select('div.r-ent div.title a[href]'):\n",
    "    print(a.get_text())\n",
    "    print(a['href']) # 或是 a.get('href') \n",
    "    \n",
    "    # 加入列表資訊\n",
    "    list_posts.append({\n",
    "        'title': a.get_text(),\n",
    "        'link': 'https://www.ptt.cc' + a['href']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 走訪每一個 a link，整合網頁內文\n",
    "for index, obj in enumerate(list_posts):\n",
    "    res_ = req.get(obj['link'])\n",
    "    soup_ = bs(res_.text, \"lxml\")\n",
    "    \n",
    "    # 去掉 div.article-metaline (作者、標題、時間…等)\n",
    "    for div in soup_.select('div[class^=\"article-metaline\"]'):\n",
    "        div.decompose()\n",
    "        \n",
    "    # 去掉 div.push (推文: 推、→、噓) (判斷元素是否存在)\n",
    "    if len( soup_.select('div.push') ) > 0:\n",
    "        for div in soup_.select('div.push'):\n",
    "            div.decompose()\n",
    "    \n",
    "    # 取得實際需要的內容 (類似 JavaScript 的 innerHTML)\n",
    "    html = soup_.select_one('div#main-content').decode_contents()\n",
    "    # html = str(soup_.select_one('div#main-content')) # 類似 JavaScript outerHTML\n",
    "    \n",
    "    # 預覽列表和內文\n",
    "    print(obj['title'])\n",
    "    print(obj['link'])\n",
    "    print(html)\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 整合到列表資訊的變數當中\n",
    "    list_posts[index]['html'] = html\n",
    "\n",
    "\n",
    "# 預覽所有結果\n",
    "pprint(list_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 思考\n",
    "- 如何取得**多個分頁**的內容?\n",
    "  - 觀察分頁數字在網址的呈現方式\n",
    "  - 將觀察到的分頁數字嵌入對應的網址當中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清空放置列表資訊的變數\n",
    "list_posts.clear()\n",
    "\n",
    "# 起始頁數\n",
    "init_page = 6503\n",
    "\n",
    "# 最新頁數\n",
    "latest_page = 6504\n",
    "\n",
    "# 在已經知道分頁數的情況下\n",
    "for page in range(init_page, latest_page + 1):\n",
    "    \n",
    "    # 取得新聞列表\n",
    "    url = f\"https://www.ptt.cc/bbs/NBA/index{page}.html\" \n",
    "\n",
    "    # 用 requests 的 get 方法把網頁抓下來\n",
    "    res = req.get(url) \n",
    "\n",
    "    # 指定 lxml 作為解析器\n",
    "    soup = bs(res.text, \"lxml\") \n",
    "    \n",
    "    # 取得 列表 的文字與超連結\n",
    "    for a in soup.select('div.r-ent div.title a[href]'):\n",
    "        # 加入列表資訊\n",
    "        list_posts.append({\n",
    "            'title': a.get_text(),\n",
    "            'link': 'https://www.ptt.cc' + a['href']\n",
    "        })\n",
    "        \n",
    "# 走訪每一個 a link，整合網頁內文\n",
    "for index, obj in enumerate(list_posts):\n",
    "    res_ = req.get(obj['link'])\n",
    "    soup_ = bs(res_.text, \"lxml\")\n",
    "\n",
    "    # 去掉 div.article-metaline (作者、標題、時間…等)\n",
    "    for div in soup_.select('div[class^=\"article-metaline\"]'):\n",
    "        div.decompose()\n",
    "        \n",
    "    # 去掉 div.push (推文: 推、→、噓) (判斷去掉元素是否存在)\n",
    "    if len( soup_.select('div.push') ) > 0:\n",
    "        for div in soup_.select('div.push'):\n",
    "            div.decompose()\n",
    "\n",
    "    # 取得實際需要的內容 (類似 JavaScript 的 innerHTML)\n",
    "    html = soup_.select_one('div#main-content').decode_contents()\n",
    "\n",
    "    # 整合到列表資訊的變數當中\n",
    "    list_posts[index]['html'] = html\n",
    "\n",
    "        \n",
    "# 預覽所有結果\n",
    "pprint(list_posts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "585a938ec471c889bf0cce0aed741a99eaf47ca09c0fa8393793bc5bfe77ba11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
